{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuai Ding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1588537568418,
     "user": {
      "displayName": "Michael D. Parrott",
      "photoUrl": "",
      "userId": "13070067452828357902"
     },
     "user_tz": 240
    },
    "id": "YoqSwgStNzT4",
    "outputId": "54026bd0-c8b5-43b2-c910-fb4b43666452"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Visualize the categories of your target variable and describe the dataset generally (the data includes news articles from the BBC news.)  A simple description is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df['category'],  color=\"#c0e0e0\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains five categories of BBC news. The number of data points are fairly equal so it's unnecessary to worry about imbalance between classes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Preprocess your data such that each document in the data is represented as a sequence of equal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29726 unique tokens.\n",
      "Shape of data tensor: (2225, 200)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the data into one hot vectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 200  # We will cut reviews after 100 words\n",
    "#training_samples = 200  # We will be training on 200 samples\n",
    "#validation_samples =   # We will be validating on 10000 samples\n",
    "max_words = 10000  # We will only consider the top 10,000 words in the dataset\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text']) # converts words in each text to each word's numeric index in tokenizer dictionary.\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (2225, 5)\n"
     ]
    }
   ],
   "source": [
    "# label encode and one-hot encode y\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df['category'])\n",
    "cat_labels = encoder.transform(df['category'])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "cat_labels = cat_labels.reshape((2225, 1))\n",
    "labels = encoder.fit_transform(cat_labels)\n",
    "\n",
    "print('Shape of label tensor:', labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set\n",
    "# But first, shuffle the data, since we started from data\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data, random_state=777, train_size=0.8)\n",
    "train_cat, test_cat = train_test_split(labels, random_state=777, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data train_data: (1780, 200)\n",
      "Shape of data test_data: (445, 200)\n",
      "Shape of train_cat: (1780, 5)\n",
      "Shape of test_cat: (445, 5)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data train_data:', train_data.shape)\n",
    "print('Shape of data test_data:', test_data.shape)\n",
    "print('Shape of train_cat:', train_cat.shape)\n",
    "print('Shape of test_cat:', test_cat.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3)  Use the data to fit separate models to each of the following architectures:\n",
    "\n",
    "A. A model with an embedding layer and dense layers (but w/ no layers meant for sequential data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 200, 10)           100000    \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 512)               1024512   \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 1,127,077\n",
      "Trainable params: 1,127,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1424 samples, validate on 356 samples\n",
      "Epoch 1/10\n",
      "1424/1424 [==============================] - 7s 5ms/step - loss: 1.5579 - acc: 0.3244 - val_loss: 1.4220 - val_acc: 0.4551\n",
      "Epoch 2/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.7744 - acc: 0.8455 - val_loss: 0.6577 - val_acc: 0.7556\n",
      "Epoch 3/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0725 - acc: 0.9958 - val_loss: 0.4450 - val_acc: 0.8427\n",
      "Epoch 4/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4133 - val_acc: 0.8624\n",
      "Epoch 5/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.4025 - val_acc: 0.8567\n",
      "Epoch 6/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.3962 - val_acc: 0.8567\n",
      "Epoch 7/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.3913 - val_acc: 0.8567\n",
      "Epoch 8/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.3870 - val_acc: 0.8624\n",
      "Epoch 9/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3860 - val_acc: 0.8624\n",
      "Epoch 10/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.3835 - val_acc: 0.8624\n",
      "445/445 [==============================] - 0s 127us/step\n",
      "Test score: 0.4491569933596622\n",
      "Test accuracy: 0.8157303361410505\n"
     ]
    }
   ],
   "source": [
    "# Let's start with a model that ignores the sequential steps that make up each observation\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "# Specify the size of your vocabulary (i.e.-10,000 terms)\n",
    "# Specify the number of features you want to extract via fitting weights to your embedding matrix.\n",
    "# We also specify the maximum input length to our Embedding layer\n",
    "# so we can later flatten the embedded inputs \n",
    "model.add(Embedding(10000, 10, input_length=maxlen))\n",
    "# After the Embedding layer, \n",
    "# our activations have shape `(samples, maxlen, 8)`.\n",
    "\n",
    "# We flatten the 3D tensor of embeddings \n",
    "# into a 2D tensor of shape `(samples, maxlen * 8)`\n",
    "model.add(Flatten())\n",
    "\n",
    "# We add the classifier on top\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_data, train_cat,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)\n",
    "score, acc = model.evaluate(test_data, test_cat,\n",
    "                            batch_size=32)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. A model using an Embedding layer with Conv1d Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 200, 10)           100000    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 193, 32)           2592      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 38, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1216)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               623104    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 728,261\n",
      "Trainable params: 728,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1424 samples, validate on 356 samples\n",
      "Epoch 1/10\n",
      "1424/1424 [==============================] - 11s 8ms/step - loss: 1.5957 - acc: 0.2402 - val_loss: 1.5677 - val_acc: 0.2444\n",
      "Epoch 2/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.2915 - acc: 0.4831 - val_loss: 1.0511 - val_acc: 0.5056\n",
      "Epoch 3/10\n",
      "1424/1424 [==============================] - 2s 2ms/step - loss: 0.5770 - acc: 0.8174 - val_loss: 0.6193 - val_acc: 0.7500\n",
      "Epoch 4/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.1094 - acc: 0.9803 - val_loss: 0.3190 - val_acc: 0.8848\n",
      "Epoch 5/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0184 - acc: 0.9986 - val_loss: 0.3183 - val_acc: 0.8989\n",
      "Epoch 6/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.3253 - val_acc: 0.8961\n",
      "Epoch 7/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.3284 - val_acc: 0.8933\n",
      "Epoch 8/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.3337 - val_acc: 0.8933\n",
      "Epoch 9/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3382 - val_acc: 0.8961\n",
      "Epoch 10/10\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.3434 - val_acc: 0.8961\n",
      "445/445 [==============================] - 0s 382us/step\n",
      "Test score: 0.3019929179314817\n",
      "Test accuracy: 0.9191011250688789\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 10, input_length=maxlen))\n",
    "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_data, train_cat,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)\n",
    "score, acc = model.evaluate(test_data, test_cat,\n",
    "                            batch_size=32)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. A model using an Embedding layer with one sequential layer (LSTM or GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 200, 10)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 10)                840       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 100,895\n",
      "Trainable params: 100,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1424 samples, validate on 356 samples\n",
      "Epoch 1/10\n",
      "1424/1424 [==============================] - 22s 15ms/step - loss: 1.6049 - acc: 0.2303 - val_loss: 1.6021 - val_acc: 0.2528\n",
      "Epoch 2/10\n",
      "1424/1424 [==============================] - 19s 13ms/step - loss: 1.5829 - acc: 0.2633 - val_loss: 1.5726 - val_acc: 0.2584\n",
      "Epoch 3/10\n",
      "1424/1424 [==============================] - 18s 13ms/step - loss: 1.3800 - acc: 0.4199 - val_loss: 1.3421 - val_acc: 0.4579\n",
      "Epoch 4/10\n",
      "1424/1424 [==============================] - 20s 14ms/step - loss: 1.1678 - acc: 0.5583 - val_loss: 1.1869 - val_acc: 0.4860\n",
      "Epoch 5/10\n",
      "1424/1424 [==============================] - 20s 14ms/step - loss: 1.0691 - acc: 0.6053 - val_loss: 1.1174 - val_acc: 0.5365\n",
      "Epoch 6/10\n",
      "1424/1424 [==============================] - 23s 16ms/step - loss: 0.9300 - acc: 0.6524 - val_loss: 1.0859 - val_acc: 0.5590\n",
      "Epoch 7/10\n",
      "1424/1424 [==============================] - 20s 14ms/step - loss: 0.8791 - acc: 0.6334 - val_loss: 1.0336 - val_acc: 0.5562\n",
      "Epoch 8/10\n",
      "1424/1424 [==============================] - 21s 15ms/step - loss: 0.8233 - acc: 0.6657 - val_loss: 1.0009 - val_acc: 0.5309\n",
      "Epoch 9/10\n",
      "1424/1424 [==============================] - 26s 18ms/step - loss: 0.7771 - acc: 0.6931 - val_loss: 1.0222 - val_acc: 0.5534\n",
      "Epoch 10/10\n",
      "1424/1424 [==============================] - 18s 13ms/step - loss: 0.7157 - acc: 0.7107 - val_loss: 1.0043 - val_acc: 0.5730\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 10,input_length=maxlen))\n",
    "model.add(LSTM(10))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_data, train_cat,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. A model using an Embedding layer with stacked sequential layers (LSTM or GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 200, 10)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 200, 10)           840       \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 200, 10)           840       \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 10)                840       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 102,575\n",
      "Trainable params: 102,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1424 samples, validate on 356 samples\n",
      "Epoch 1/10\n",
      "1424/1424 [==============================] - 68s 48ms/step - loss: 1.6064 - acc: 0.2268 - val_loss: 1.6047 - val_acc: 0.2079\n",
      "Epoch 2/10\n",
      "1424/1424 [==============================] - 60s 42ms/step - loss: 1.5405 - acc: 0.2521 - val_loss: 1.3753 - val_acc: 0.4410\n",
      "Epoch 3/10\n",
      "1424/1424 [==============================] - 54s 38ms/step - loss: 1.2977 - acc: 0.3876 - val_loss: 1.2224 - val_acc: 0.4494\n",
      "Epoch 4/10\n",
      "1424/1424 [==============================] - 55s 39ms/step - loss: 1.1976 - acc: 0.4017 - val_loss: 1.2014 - val_acc: 0.4747\n",
      "Epoch 5/10\n",
      "1424/1424 [==============================] - 53s 37ms/step - loss: 1.0567 - acc: 0.5162 - val_loss: 1.0601 - val_acc: 0.5590\n",
      "Epoch 6/10\n",
      "1424/1424 [==============================] - 53s 37ms/step - loss: 0.8892 - acc: 0.6011 - val_loss: 1.0446 - val_acc: 0.5618\n",
      "Epoch 7/10\n",
      "1424/1424 [==============================] - 60s 42ms/step - loss: 0.8227 - acc: 0.5906 - val_loss: 0.9856 - val_acc: 0.5197\n",
      "Epoch 8/10\n",
      "1424/1424 [==============================] - 56s 39ms/step - loss: 0.7398 - acc: 0.6468 - val_loss: 0.8902 - val_acc: 0.6348\n",
      "Epoch 9/10\n",
      "1424/1424 [==============================] - 49s 35ms/step - loss: 0.5665 - acc: 0.7458 - val_loss: 0.8237 - val_acc: 0.6657\n",
      "Epoch 10/10\n",
      "1424/1424 [==============================] - 48s 34ms/step - loss: 0.4788 - acc: 0.7935 - val_loss: 0.7601 - val_acc: 0.7388\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 10,input_length=maxlen))\n",
    "model.add(LSTM(10, return_sequences=True))\n",
    "model.add(LSTM(10, return_sequences=True))\n",
    "model.add(LSTM(10))\n",
    "          \n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_data, train_cat,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. A model using an Embedding layer with bidirectional sequential layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 200, 10)           100000    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 20)                1680      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 101,785\n",
      "Trainable params: 101,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1424 samples, validate on 356 samples\n",
      "Epoch 1/15\n",
      "1424/1424 [==============================] - 43s 30ms/step - loss: 1.6016 - acc: 0.2303 - val_loss: 1.5967 - val_acc: 0.2416\n",
      "Epoch 2/15\n",
      "1424/1424 [==============================] - 49s 35ms/step - loss: 1.5510 - acc: 0.3006 - val_loss: 1.4681 - val_acc: 0.3876\n",
      "Epoch 3/15\n",
      "1424/1424 [==============================] - 32s 22ms/step - loss: 1.3153 - acc: 0.4670 - val_loss: 1.4873 - val_acc: 0.3764\n",
      "Epoch 4/15\n",
      "1424/1424 [==============================] - 27s 19ms/step - loss: 1.1994 - acc: 0.6875 - val_loss: 1.2189 - val_acc: 0.5927\n",
      "Epoch 5/15\n",
      "1424/1424 [==============================] - 27s 19ms/step - loss: 1.0513 - acc: 0.6861 - val_loss: 1.0283 - val_acc: 0.7303\n",
      "Epoch 6/15\n",
      "1424/1424 [==============================] - 26s 19ms/step - loss: 0.8443 - acc: 0.8722 - val_loss: 0.9798 - val_acc: 0.7191\n",
      "Epoch 7/15\n",
      "1424/1424 [==============================] - 27s 19ms/step - loss: 0.7385 - acc: 0.8525 - val_loss: 0.9585 - val_acc: 0.7163\n",
      "Epoch 8/15\n",
      "1424/1424 [==============================] - 32s 22ms/step - loss: 0.6481 - acc: 0.8027 - val_loss: 0.8582 - val_acc: 0.7191\n",
      "Epoch 9/15\n",
      "1424/1424 [==============================] - 27s 19ms/step - loss: 0.5942 - acc: 0.8301 - val_loss: 1.7598 - val_acc: 0.5197\n",
      "Epoch 10/15\n",
      "1424/1424 [==============================] - 27s 19ms/step - loss: 1.4430 - acc: 0.4600 - val_loss: 1.4124 - val_acc: 0.3764\n",
      "Epoch 11/15\n",
      "1424/1424 [==============================] - 28s 19ms/step - loss: 1.0292 - acc: 0.5147 - val_loss: 1.1208 - val_acc: 0.6039\n",
      "Epoch 12/15\n",
      "1424/1424 [==============================] - 25s 18ms/step - loss: 0.7488 - acc: 0.7079 - val_loss: 0.9779 - val_acc: 0.6545\n",
      "Epoch 13/15\n",
      "1424/1424 [==============================] - 26s 18ms/step - loss: 0.5863 - acc: 0.8729 - val_loss: 0.8216 - val_acc: 0.7640\n",
      "Epoch 14/15\n",
      "1424/1424 [==============================] - 25s 18ms/step - loss: 0.5022 - acc: 0.9192 - val_loss: 0.7706 - val_acc: 0.7416\n",
      "Epoch 15/15\n",
      "1424/1424 [==============================] - 26s 18ms/step - loss: 0.4552 - acc: 0.9185 - val_loss: 0.7122 - val_acc: 0.7528\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 10,input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(10)))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_data, train_cat,\n",
    "                    epochs=15,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F. Now retrain your best model from C, D, and E using dropout (you may need to increase epochs!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 200, 10)           100000    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 20)                1680      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 101,785\n",
      "Trainable params: 101,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1424 samples, validate on 356 samples\n",
      "Epoch 1/15\n",
      "1424/1424 [==============================] - 45s 32ms/step - loss: 1.6065 - acc: 0.2296 - val_loss: 1.6035 - val_acc: 0.2331\n",
      "Epoch 2/15\n",
      "1424/1424 [==============================] - 31s 22ms/step - loss: 1.5886 - acc: 0.3097 - val_loss: 1.5864 - val_acc: 0.3315\n",
      "Epoch 3/15\n",
      "1424/1424 [==============================] - 31s 22ms/step - loss: 1.4831 - acc: 0.3961 - val_loss: 1.3621 - val_acc: 0.4831\n",
      "Epoch 4/15\n",
      "1424/1424 [==============================] - 31s 22ms/step - loss: 1.3189 - acc: 0.5014 - val_loss: 1.3371 - val_acc: 0.4691\n",
      "Epoch 5/15\n",
      "1424/1424 [==============================] - 32s 22ms/step - loss: 1.2585 - acc: 0.5288 - val_loss: 1.1181 - val_acc: 0.5534\n",
      "Epoch 6/15\n",
      "1424/1424 [==============================] - 31s 22ms/step - loss: 1.1311 - acc: 0.6011 - val_loss: 1.0458 - val_acc: 0.5815\n",
      "Epoch 7/15\n",
      "1424/1424 [==============================] - 33s 23ms/step - loss: 1.1255 - acc: 0.5400 - val_loss: 1.0356 - val_acc: 0.5899\n",
      "Epoch 8/15\n",
      "1424/1424 [==============================] - 33s 23ms/step - loss: 1.0722 - acc: 0.6159 - val_loss: 1.0718 - val_acc: 0.5702\n",
      "Epoch 9/15\n",
      "1424/1424 [==============================] - 31s 22ms/step - loss: 1.0089 - acc: 0.6461 - val_loss: 0.9517 - val_acc: 0.6545\n",
      "Epoch 10/15\n",
      "1424/1424 [==============================] - 39s 27ms/step - loss: 0.8794 - acc: 0.7472 - val_loss: 0.8738 - val_acc: 0.7219\n",
      "Epoch 11/15\n",
      "1424/1424 [==============================] - 32s 22ms/step - loss: 0.8160 - acc: 0.7598 - val_loss: 0.8536 - val_acc: 0.7331\n",
      "Epoch 12/15\n",
      "1424/1424 [==============================] - 31s 22ms/step - loss: 0.7535 - acc: 0.7999 - val_loss: 0.7886 - val_acc: 0.7640\n",
      "Epoch 13/15\n",
      "1424/1424 [==============================] - 31s 22ms/step - loss: 0.6822 - acc: 0.8167 - val_loss: 0.7537 - val_acc: 0.7809\n",
      "Epoch 14/15\n",
      "1424/1424 [==============================] - 31s 22ms/step - loss: 0.6303 - acc: 0.8209 - val_loss: 0.7572 - val_acc: 0.7669\n",
      "Epoch 15/15\n",
      "1424/1424 [==============================] - 31s 22ms/step - loss: 0.5804 - acc: 0.8539 - val_loss: 0.7215 - val_acc: 0.7781\n",
      "445/445 [==============================] - 1s 3ms/step\n",
      "Test score: 0.633648742450757\n",
      "Test accuracy: 0.8179775298311469\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 10,input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(10,dropout=0.2, recurrent_dropout=0.2)))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_data, train_cat,\n",
    "                    epochs=15,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)\n",
    "score, acc = model.evaluate(test_data, test_cat,\n",
    "                            batch_size=32)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Discuss 1) which model(s) performed best and speculate about 2) how you might try to further improve the predictive power of your model (e.g. Glove embeddings? More layers? Combining Conv1D with LSTM layers? More LSTM hidden nodes?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A model using an embedding layer with bidirectional sequential layers and dropout performed best. In that model, loss was decreasing and val_loss was also decreasing. So I may increase epochs and I add more LSTM hidden nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPt/UwRdMuRlA1Q6rqKri/Y",
   "name": "BBC News Category Classification Mini-Hackathon.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
